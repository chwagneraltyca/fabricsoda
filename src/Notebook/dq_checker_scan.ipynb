{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fabric Python Notebook - DQ Checker Scan Executor\n",
        "# ============================================================================\n",
        "# Execute data quality checks against Fabric Data Warehouse using Soda Core.\n",
        "# Designed for Fabric Pipeline integration with parameterized execution.\n",
        "# ============================================================================"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DQ Checker - Soda Core Scan Executor\n",
        "\n",
        "**Execution Flow:**\n",
        "```\n",
        "Parameters → Read Config → Generate YAML → Execute Soda → Write Results\n",
        "```\n",
        "\n",
        "**Pipeline Integration:** Pass parameters via Fabric Pipeline activity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies (cached after first run)\n",
        "%pip install soda-core-sqlserver --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parameters\n",
        "\n",
        "Configure execution via Fabric Pipeline parameters or manual override."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# PIPELINE PARAMETERS\n",
        "# =============================================================================\n",
        "# These values are set by Fabric Pipeline or manually for testing.\n",
        "# In Pipeline: Use \"Parameters\" section of notebook activity.\n",
        "\n",
        "# Execution scope\n",
        "SUITE_ID: int = 1                    # Suite to execute (0 = use TESTCASE_IDS)\n",
        "TESTCASE_IDS: str = \"\"               # Comma-separated testcase IDs (optional)\n",
        "\n",
        "# Pipeline behavior\n",
        "FAIL_ON_ERROR: bool = True           # Raise exception if any check fails\n",
        "SMOKE_TEST: bool = False             # True = test connection only, skip execution\n",
        "\n",
        "# =============================================================================\n",
        "# KEY VAULT CONFIGURATION\n",
        "# =============================================================================\n",
        "# All secrets and configuration come from Key Vault\n",
        "KEY_VAULT_URI: str = \"https://chwakv.vault.azure.net/\"\n",
        "\n",
        "# Secret names in Key Vault\n",
        "SECRET_CLIENT_ID: str = \"dq-checker-spn-client-id\"\n",
        "SECRET_CLIENT_SECRET: str = \"dq-checker-spn-secret\"\n",
        "SECRET_META_DB_SERVER: str = \"dq-checker-meta-db-server\"\n",
        "SECRET_META_DB_NAME: str = \"dq-checker-meta-db-name\"\n",
        "\n",
        "# =============================================================================\n",
        "# ONELAKE OUTPUT\n",
        "# =============================================================================\n",
        "LAKEHOUSE_PATH: str = \"/lakehouse/default/Files\"\n",
        "LOGS_FOLDER: str = \"dq_logs\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports & Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "import uuid\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Optional, Any\n",
        "from dataclasses import dataclass, field\n",
        "\n",
        "import pandas as pd\n",
        "import pyodbc\n",
        "from soda.scan import Scan\n",
        "import notebookutils\n",
        "\n",
        "# Generate unique run identifier\n",
        "RUN_ID = str(uuid.uuid4())[:8]\n",
        "print(f\"DQ Checker Scan - Run ID: {RUN_ID}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class DQConfig:\n",
        "    \"\"\"Configuration for DQ Checker execution.\"\"\"\n",
        "\n",
        "    # Credentials (from Key Vault)\n",
        "    client_id: str = \"\"\n",
        "    client_secret: str = \"\"\n",
        "\n",
        "    # Metadata DB connection\n",
        "    meta_db_server: str = \"\"\n",
        "    meta_db_name: str = \"\"\n",
        "\n",
        "    # Execution parameters\n",
        "    suite_id: int = 0\n",
        "    testcase_ids: List[int] = field(default_factory=list)\n",
        "    fail_on_error: bool = True\n",
        "    smoke_test: bool = False\n",
        "\n",
        "    # Output paths\n",
        "    lakehouse_path: str = \"/lakehouse/default/Files\"\n",
        "    logs_folder: str = \"dq_logs\"\n",
        "\n",
        "    @classmethod\n",
        "    def from_keyvault(cls, kv_uri: str, **overrides) -> \"DQConfig\":\n",
        "        \"\"\"\n",
        "        Load configuration from Azure Key Vault.\n",
        "\n",
        "        Args:\n",
        "            kv_uri: Key Vault URI\n",
        "            **overrides: Override specific config values\n",
        "\n",
        "        Returns:\n",
        "            Configured DQConfig instance\n",
        "        \"\"\"\n",
        "        def get_secret(name: str, default: str = \"\") -> str:\n",
        "            try:\n",
        "                return notebookutils.credentials.getSecret(kv_uri, name)\n",
        "            except Exception:\n",
        "                return default\n",
        "\n",
        "        config = cls(\n",
        "            client_id=get_secret(SECRET_CLIENT_ID),\n",
        "            client_secret=get_secret(SECRET_CLIENT_SECRET),\n",
        "            meta_db_server=get_secret(SECRET_META_DB_SERVER),\n",
        "            meta_db_name=get_secret(SECRET_META_DB_NAME),\n",
        "        )\n",
        "\n",
        "        # Apply overrides\n",
        "        for key, value in overrides.items():\n",
        "            if hasattr(config, key):\n",
        "                setattr(config, key, value)\n",
        "\n",
        "        return config\n",
        "\n",
        "\n",
        "# Load configuration\n",
        "config = DQConfig.from_keyvault(\n",
        "    KEY_VAULT_URI,\n",
        "    suite_id=SUITE_ID,\n",
        "    testcase_ids=[int(x.strip()) for x in TESTCASE_IDS.split(\",\") if x.strip()],\n",
        "    fail_on_error=FAIL_ON_ERROR,\n",
        "    smoke_test=SMOKE_TEST,\n",
        "    lakehouse_path=LAKEHOUSE_PATH,\n",
        "    logs_folder=LOGS_FOLDER,\n",
        ")\n",
        "\n",
        "print(f\"Suite ID: {config.suite_id}\")\n",
        "print(f\"Testcase IDs: {config.testcase_ids or 'All in suite'}\")\n",
        "print(f\"Fail on Error: {config.fail_on_error}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Database Connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MetadataDB:\n",
        "    \"\"\"Connection manager for DQ Checker metadata database.\"\"\"\n",
        "\n",
        "    def __init__(self, config: DQConfig):\n",
        "        self.config = config\n",
        "        self._conn: Optional[pyodbc.Connection] = None\n",
        "\n",
        "    def connect(self) -> pyodbc.Connection:\n",
        "        \"\"\"Establish database connection using Service Principal auth.\"\"\"\n",
        "        if self._conn is None:\n",
        "            conn_str = (\n",
        "                f\"Driver={{ODBC Driver 18 for SQL Server}};\"\n",
        "                f\"Server={self.config.meta_db_server},1433;\"\n",
        "                f\"Database={self.config.meta_db_name};\"\n",
        "                f\"Authentication=ActiveDirectoryServicePrincipal;\"\n",
        "                f\"UID={self.config.client_id};\"\n",
        "                f\"PWD={self.config.client_secret};\"\n",
        "                f\"Encrypt=yes;TrustServerCertificate=no;\"\n",
        "            )\n",
        "            self._conn = pyodbc.connect(conn_str)\n",
        "        return self._conn\n",
        "\n",
        "    def close(self):\n",
        "        \"\"\"Close database connection.\"\"\"\n",
        "        if self._conn:\n",
        "            self._conn.close()\n",
        "            self._conn = None\n",
        "\n",
        "    def query(self, sql: str) -> pd.DataFrame:\n",
        "        \"\"\"Execute query and return DataFrame.\"\"\"\n",
        "        conn = self.connect()\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(sql)\n",
        "        columns = [col[0] for col in cursor.description]\n",
        "        rows = cursor.fetchall()\n",
        "        return pd.DataFrame.from_records(rows, columns=columns)\n",
        "\n",
        "    def execute(self, sql: str) -> Any:\n",
        "        \"\"\"Execute SQL and return first result.\"\"\"\n",
        "        conn = self.connect()\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(sql)\n",
        "        result = cursor.fetchone()\n",
        "        conn.commit()\n",
        "        return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Source Manager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class DataSource:\n",
        "    \"\"\"Represents a data source from dq_sources table.\"\"\"\n",
        "    source_id: int\n",
        "    source_name: str\n",
        "    source_type: str\n",
        "    server_name: str\n",
        "    database_name: str\n",
        "    keyvault_uri: Optional[str] = None\n",
        "    client_id: Optional[str] = None\n",
        "    secret_name: Optional[str] = None\n",
        "\n",
        "    def get_credentials(self, default_config: DQConfig) -> tuple:\n",
        "        \"\"\"\n",
        "        Get credentials for this source.\n",
        "\n",
        "        Uses source-specific credentials if defined, otherwise falls back to defaults.\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (client_id, client_secret)\n",
        "        \"\"\"\n",
        "        # Use source-specific or default client_id\n",
        "        cid = self.client_id or default_config.client_id\n",
        "\n",
        "        # Get secret from source-specific or default Key Vault\n",
        "        kv_uri = self.keyvault_uri or KEY_VAULT_URI\n",
        "        secret_name = self.secret_name or SECRET_CLIENT_SECRET\n",
        "\n",
        "        secret = notebookutils.credentials.getSecret(kv_uri, secret_name)\n",
        "        return cid, secret\n",
        "\n",
        "    def get_soda_yaml(self, client_id: str, client_secret: str) -> str:\n",
        "        \"\"\"Generate Soda connection YAML for this source.\"\"\"\n",
        "        return f\"\"\"\n",
        "data_source {self.source_name}:\n",
        "  type: sqlserver\n",
        "  driver: ODBC Driver 18 for SQL Server\n",
        "  host: {self.server_name}\n",
        "  port: '1433'\n",
        "  database: {self.database_name}\n",
        "  authentication: ActiveDirectoryServicePrincipal\n",
        "  username: {client_id}\n",
        "  password: {client_secret}\n",
        "  encrypt: true\n",
        "  trust_server_certificate: false\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class DataSourceManager:\n",
        "    \"\"\"Manages data sources from metadata database.\"\"\"\n",
        "\n",
        "    def __init__(self, db: MetadataDB):\n",
        "        self.db = db\n",
        "        self._cache: Dict[int, DataSource] = {}\n",
        "\n",
        "    def get(self, source_id: int) -> DataSource:\n",
        "        \"\"\"Get data source by ID.\"\"\"\n",
        "        if source_id not in self._cache:\n",
        "            df = self.db.query(f\"\"\"\n",
        "                SELECT source_id, source_name, source_type, server_name,\n",
        "                       database_name, keyvault_uri, client_id, secret_name\n",
        "                FROM dq_sources WHERE source_id = {source_id}\n",
        "            \"\"\")\n",
        "            if df.empty:\n",
        "                raise ValueError(f\"Data source {source_id} not found\")\n",
        "            row = df.iloc[0]\n",
        "            self._cache[source_id] = DataSource(\n",
        "                source_id=row['source_id'],\n",
        "                source_name=row['source_name'],\n",
        "                source_type=row['source_type'] or 'fabric_warehouse',\n",
        "                server_name=row['server_name'],\n",
        "                database_name=row['database_name'],\n",
        "                keyvault_uri=row['keyvault_uri'],\n",
        "                client_id=row['client_id'],\n",
        "                secret_name=row['secret_name'],\n",
        "            )\n",
        "        return self._cache[source_id]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## YAML Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SodaYAMLGenerator:\n",
        "    \"\"\"\n",
        "    Generates SodaCL YAML from check definitions.\n",
        "\n",
        "    Supports all 22 Soda check types including freshness, schema,\n",
        "    reference, scalar comparison, and custom SQL.\n",
        "    \"\"\"\n",
        "\n",
        "    YAML_SPECIAL_CHARS = {':', '#', '{', '}', '[', ']', '&', '*', '!', '|', '>', '@', '`', '%'}\n",
        "\n",
        "    @staticmethod\n",
        "    def safe_value(value: Optional[str]) -> str:\n",
        "        \"\"\"Escape special characters for YAML output.\"\"\"\n",
        "        if value is None:\n",
        "            return ''\n",
        "        if not isinstance(value, str):\n",
        "            value = str(value)\n",
        "        value = value.strip()\n",
        "        if not value:\n",
        "            return ''\n",
        "\n",
        "        if '\\n' in value:\n",
        "            indented = '\\n        '.join(value.split('\\n'))\n",
        "            return f'|\\n        {indented}'\n",
        "\n",
        "        needs_quoting = (\n",
        "            any(c in value for c in SodaYAMLGenerator.YAML_SPECIAL_CHARS) or\n",
        "            value.startswith(\"'\") or value.startswith('\"') or\n",
        "            value.startswith(' ') or value.endswith(' ')\n",
        "        )\n",
        "\n",
        "        if needs_quoting:\n",
        "            escaped = value.replace('\\\\', '\\\\\\\\').replace('\"', '\\\\\"')\n",
        "            return f'\"{escaped}\"'\n",
        "\n",
        "        return value\n",
        "\n",
        "    def generate(self, checks_df: pd.DataFrame) -> str:\n",
        "        \"\"\"\n",
        "        Generate SodaCL YAML from checks DataFrame.\n",
        "\n",
        "        Args:\n",
        "            checks_df: DataFrame with check definitions from vw_checks_complete\n",
        "\n",
        "        Returns:\n",
        "            SodaCL YAML string\n",
        "        \"\"\"\n",
        "        if checks_df.empty:\n",
        "            return \"# No checks defined\\n\"\n",
        "\n",
        "        yaml_lines = []\n",
        "\n",
        "        for (schema_name, table_name), table_checks in checks_df.groupby(['schema_name', 'table_name']):\n",
        "            table_str = str(table_name)\n",
        "\n",
        "            # Handle special characters in table names\n",
        "            if ' ' in table_str or '-' in table_str:\n",
        "                fq_table = f'\"{table_str}\"'\n",
        "            elif pd.notna(schema_name) and '.' not in table_str:\n",
        "                fq_table = f\"{schema_name}.{table_str}\"\n",
        "            else:\n",
        "                fq_table = table_str\n",
        "\n",
        "            check_lines = []\n",
        "            for _, check in table_checks.iterrows():\n",
        "                check_lines.extend(self._generate_check(check))\n",
        "\n",
        "            if check_lines:\n",
        "                yaml_lines.append(f\"checks for {fq_table}:\")\n",
        "                yaml_lines.extend(check_lines)\n",
        "                yaml_lines.append(\"\")\n",
        "\n",
        "        return \"\\n\".join(yaml_lines)\n",
        "\n",
        "    def _generate_check(self, check: pd.Series) -> List[str]:\n",
        "        \"\"\"Generate YAML for a single check.\"\"\"\n",
        "        metric = check['metric']\n",
        "\n",
        "        # Route to specialized generators\n",
        "        generators = {\n",
        "            'freshness': self._gen_freshness,\n",
        "            'schema': self._gen_schema,\n",
        "            'reference': self._gen_reference,\n",
        "            'user_defined': self._gen_custom_sql,\n",
        "            'custom_sql': self._gen_custom_sql,\n",
        "            'scalar_comparison': self._gen_scalar,\n",
        "        }\n",
        "\n",
        "        if metric in generators:\n",
        "            return generators[metric](check)\n",
        "\n",
        "        return self._gen_standard(check)\n",
        "\n",
        "    def _gen_standard(self, check: pd.Series) -> List[str]:\n",
        "        \"\"\"Generate standard metric check.\"\"\"\n",
        "        lines = []\n",
        "        metric = check['metric']\n",
        "        column = check.get('column_name_quoted') or check.get('column_name')\n",
        "\n",
        "        column_metrics = [\n",
        "            'missing_count', 'missing_percent', 'duplicate_count', 'duplicate_percent',\n",
        "            'min', 'max', 'avg', 'sum', 'invalid_count', 'invalid_percent',\n",
        "            'valid_count', 'avg_length', 'min_length'\n",
        "        ]\n",
        "\n",
        "        if pd.notna(column) and metric in column_metrics:\n",
        "            lines.append(f\"  - {metric}({column}):\")\n",
        "        else:\n",
        "            lines.append(f\"  - {metric}:\")\n",
        "\n",
        "        check_name = self._format_check_name(check)\n",
        "        lines.append(f'      name: \"{check_name}\"')\n",
        "        lines.extend(self._gen_thresholds(check))\n",
        "\n",
        "        return lines\n",
        "\n",
        "    def _gen_thresholds(self, check: pd.Series) -> List[str]:\n",
        "        \"\"\"Generate warn/fail threshold lines.\"\"\"\n",
        "        lines = []\n",
        "\n",
        "        if pd.notna(check.get('warn_threshold')) and pd.notna(check.get('warn_comparison')):\n",
        "            op = '=' if check['warn_comparison'] == '==' else check['warn_comparison']\n",
        "            lines.append(f\"      warn: when {op} {check['warn_threshold']}\")\n",
        "\n",
        "        if pd.notna(check.get('fail_threshold')) and pd.notna(check.get('fail_comparison')):\n",
        "            op = '=' if check['fail_comparison'] == '==' else check['fail_comparison']\n",
        "            lines.append(f\"      fail: when {op} {check['fail_threshold']}\")\n",
        "\n",
        "        return lines\n",
        "\n",
        "    def _gen_freshness(self, check: pd.Series) -> List[str]:\n",
        "        \"\"\"Generate freshness check.\"\"\"\n",
        "        if not all(pd.notna(check.get(f)) for f in ['freshness_column', 'freshness_threshold_value', 'freshness_threshold_unit']):\n",
        "            return []\n",
        "\n",
        "        col = check['freshness_column']\n",
        "        val = int(check['freshness_threshold_value']) if float(check['freshness_threshold_value']).is_integer() else check['freshness_threshold_value']\n",
        "        unit = check['freshness_threshold_unit']\n",
        "\n",
        "        return [\n",
        "            f\"  - freshness({col}) < {val}{unit}:\",\n",
        "            f'      name: \"{self._format_check_name(check)}\"'\n",
        "        ]\n",
        "\n",
        "    def _gen_schema(self, check: pd.Series) -> List[str]:\n",
        "        \"\"\"Generate schema check.\"\"\"\n",
        "        lines = [\n",
        "            \"  - schema:\",\n",
        "            f'      name: \"{self._format_check_name(check)}\"'\n",
        "        ]\n",
        "\n",
        "        if pd.notna(check.get('schema_required_columns')):\n",
        "            try:\n",
        "                required = json.loads(check['schema_required_columns'])\n",
        "                if required:\n",
        "                    lines.append(\"      fail:\")\n",
        "                    lines.append(\"        when required column missing:\")\n",
        "                    for col in required:\n",
        "                        lines.append(f\"          - {col}\")\n",
        "            except json.JSONDecodeError:\n",
        "                pass\n",
        "\n",
        "        return lines\n",
        "\n",
        "    def _gen_reference(self, check: pd.Series) -> List[str]:\n",
        "        \"\"\"Generate reference integrity check.\"\"\"\n",
        "        if not all(pd.notna(check.get(f)) for f in ['reference_table', 'reference_column']):\n",
        "            return []\n",
        "\n",
        "        src_col = check.get('column_name_quoted') or check.get('column_name')\n",
        "        ref_table = check['reference_table']\n",
        "        ref_col = check.get('reference_column_quoted') or check['reference_column']\n",
        "        src_table = check['table_name']\n",
        "        schema = check.get('schema_name', 'dbo')\n",
        "\n",
        "        return [\n",
        "            \"  - failed rows:\",\n",
        "            f'      name: \"{self._format_check_name(check)}\"',\n",
        "            \"      fail query: |\",\n",
        "            f\"        SELECT * FROM {schema}.{src_table}\",\n",
        "            f\"        WHERE {src_col} IS NOT NULL\",\n",
        "            f\"          AND {src_col} NOT IN (SELECT {ref_col} FROM dbo.{ref_table})\"\n",
        "        ]\n",
        "\n",
        "    def _gen_custom_sql(self, check: pd.Series) -> List[str]:\n",
        "        \"\"\"Generate custom SQL check.\"\"\"\n",
        "        if not pd.notna(check.get('custom_sql_query')):\n",
        "            return []\n",
        "\n",
        "        sql = str(check['custom_sql_query']).strip()\n",
        "        metric_name = re.sub(r'[^a-zA-Z0-9_]', '_', check['check_name'].lower())\n",
        "        metric_name = re.sub(r'_+', '_', metric_name).strip('_')\n",
        "\n",
        "        threshold = \"= 0\"\n",
        "        if pd.notna(check.get('fail_comparison')) and pd.notna(check.get('fail_threshold')):\n",
        "            op = '=' if check['fail_comparison'] == '==' else check['fail_comparison']\n",
        "            threshold = f\"{op} {check['fail_threshold']}\"\n",
        "\n",
        "        lines = [\n",
        "            f\"  - {metric_name} {threshold}:\",\n",
        "            f'      name: \"{self._format_check_name(check)}\"',\n",
        "            f\"      {metric_name} query: |\"\n",
        "        ]\n",
        "        for sql_line in sql.split('\\n'):\n",
        "            lines.append(f\"        {sql_line}\")\n",
        "\n",
        "        return lines\n",
        "\n",
        "    def _gen_scalar(self, check: pd.Series) -> List[str]:\n",
        "        \"\"\"Generate scalar comparison check.\"\"\"\n",
        "        if not all(pd.notna(check.get(f)) for f in ['scalar_query_a', 'scalar_query_b']):\n",
        "            return []\n",
        "\n",
        "        qa = str(check['scalar_query_a']).strip()\n",
        "        qb = str(check['scalar_query_b']).strip()\n",
        "        op = check.get('scalar_operator', '==')\n",
        "\n",
        "        where_map = {\n",
        "            '==': 'query_a != query_b', '!=': 'query_a = query_b',\n",
        "            '>': 'query_a <= query_b', '>=': 'query_a < query_b',\n",
        "            '<': 'query_a >= query_b', '<=': 'query_a > query_b'\n",
        "        }\n",
        "\n",
        "        return [\n",
        "            \"  - failed rows:\",\n",
        "            f'      name: \"{self._format_check_name(check)}\"',\n",
        "            \"      fail query: |\",\n",
        "            \"        WITH comparison AS (\",\n",
        "            f\"          SELECT ({qa}) AS query_a, ({qb}) AS query_b\",\n",
        "            \"        )\",\n",
        "            \"        SELECT query_a, query_b, query_a - query_b AS difference\",\n",
        "            \"        FROM comparison\",\n",
        "            f\"        WHERE {where_map.get(op, 'query_a != query_b')}\"\n",
        "        ]\n",
        "\n",
        "    def _format_check_name(self, check: pd.Series) -> str:\n",
        "        \"\"\"Format check name with ID for result linking.\"\"\"\n",
        "        name = check['check_name']\n",
        "        if pd.notna(check.get('check_id')):\n",
        "            name = f\"{name} [check_id:{check['check_id']}]\"\n",
        "        return name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scan Executor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class ScanResult:\n",
        "    \"\"\"Results from a Soda scan execution.\"\"\"\n",
        "    run_id: str\n",
        "    execution_log_id: int\n",
        "    total: int = 0\n",
        "    passed: int = 0\n",
        "    failed: int = 0\n",
        "    warned: int = 0\n",
        "    has_errors: bool = False\n",
        "    error_message: Optional[str] = None\n",
        "    results: List[Dict] = field(default_factory=list)\n",
        "    yaml_content: str = \"\"\n",
        "    logs: str = \"\"\n",
        "\n",
        "\n",
        "class SodaExecutor:\n",
        "    \"\"\"Executes Soda scans against data sources.\"\"\"\n",
        "\n",
        "    def __init__(self, config: DQConfig):\n",
        "        self.config = config\n",
        "\n",
        "    def execute(self, yaml_content: str, connection_yaml: str, run_id: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Execute Soda scan.\n",
        "\n",
        "        Args:\n",
        "            yaml_content: SodaCL check definitions\n",
        "            connection_yaml: Soda data source configuration\n",
        "            run_id: Unique run identifier\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with scan results, logs, and error status\n",
        "        \"\"\"\n",
        "        scan = Scan()\n",
        "        scan.set_data_source_name(\"fabric_dwh\")\n",
        "        scan.set_scan_definition_name(f\"dq_checker_{run_id}\")\n",
        "        scan.add_configuration_yaml_str(connection_yaml)\n",
        "        scan.add_sodacl_yaml_str(yaml_content)\n",
        "\n",
        "        scan.execute()\n",
        "\n",
        "        return {\n",
        "            \"results\": scan.get_scan_results(),\n",
        "            \"logs\": scan.get_logs_text(),\n",
        "            \"has_errors\": scan.has_error_logs(),\n",
        "            \"error_logs\": scan.get_error_logs_text() if scan.has_error_logs() else None\n",
        "        }\n",
        "\n",
        "    def parse_results(self, scan_results: Dict) -> List[Dict]:\n",
        "        \"\"\"Extract structured results from Soda scan output.\"\"\"\n",
        "        results = []\n",
        "\n",
        "        for check in scan_results.get('checks', []):\n",
        "            check_name = check.get('name', '')\n",
        "            check_id_match = re.search(r'\\[check_id:(\\d+)\\]', check_name)\n",
        "\n",
        "            diagnostics = check.get('diagnostics', {})\n",
        "\n",
        "            results.append({\n",
        "                'check_id': int(check_id_match.group(1)) if check_id_match else None,\n",
        "                'check_name': check_name,\n",
        "                'outcome': check.get('outcome', 'unknown'),\n",
        "                'value': diagnostics.get('value', check.get('value'))\n",
        "            })\n",
        "\n",
        "        return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Result Writer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ResultWriter:\n",
        "    \"\"\"Writes scan results to metadata DB and OneLake.\"\"\"\n",
        "\n",
        "    def __init__(self, db: MetadataDB, config: DQConfig):\n",
        "        self.db = db\n",
        "        self.config = config\n",
        "\n",
        "    def create_execution_log(self, run_id: str, suite_id: int) -> int:\n",
        "        \"\"\"Create execution log entry.\"\"\"\n",
        "        result = self.db.execute(\n",
        "            f\"EXEC sp_create_execution_log @run_id='{run_id}', @suite_id={suite_id}\"\n",
        "        )\n",
        "        return int(result[0])\n",
        "\n",
        "    def write_results(self, log_id: int, run_id: str, results: List[Dict]):\n",
        "        \"\"\"Write individual check results.\"\"\"\n",
        "        conn = self.db.connect()\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        for r in results:\n",
        "            name = str(r['check_name']).replace(\"'\", \"''\") if r['check_name'] else ''\n",
        "            outcome = str(r['outcome']).replace(\"'\", \"''\") if r['outcome'] else ''\n",
        "            check_id = r['check_id'] if r['check_id'] else 'NULL'\n",
        "            value = r['value'] if r['value'] is not None else 'NULL'\n",
        "\n",
        "            cursor.execute(f\"\"\"\n",
        "                EXEC sp_insert_result\n",
        "                    @run_id='{run_id}', @execution_log_id={log_id},\n",
        "                    @check_id={check_id}, @check_name='{name}',\n",
        "                    @check_outcome='{outcome}', @check_value={value}\n",
        "            \"\"\")\n",
        "            cursor.fetchone()\n",
        "\n",
        "        conn.commit()\n",
        "\n",
        "    def update_execution_log(self, log_id: int, result: ScanResult):\n",
        "        \"\"\"Update execution log with final status.\"\"\"\n",
        "        status = 'failed' if result.error_message else 'completed'\n",
        "        has_failures = 1 if result.failed > 0 else 0\n",
        "\n",
        "        yaml_esc = result.yaml_content.replace(\"'\", \"''\")\n",
        "        error_esc = result.error_message.replace(\"'\", \"''\") if result.error_message else ''\n",
        "        error_param = f\"'{error_esc}'\" if result.error_message else 'NULL'\n",
        "\n",
        "        self.db.execute(f\"\"\"\n",
        "            EXEC sp_update_execution_log\n",
        "                @execution_log_id={log_id}, @status='{status}',\n",
        "                @total_checks={result.total}, @checks_passed={result.passed},\n",
        "                @checks_failed={result.failed}, @checks_warned={result.warned},\n",
        "                @has_failures={has_failures}, @generated_yaml='{yaml_esc}',\n",
        "                @error_message={error_param}\n",
        "        \"\"\")\n",
        "\n",
        "    def write_to_onelake(self, result: ScanResult, suite_id: int, scan_output: Dict) -> str:\n",
        "        \"\"\"Write full results to OneLake with Hive-style partitioning.\"\"\"\n",
        "        now = datetime.utcnow()\n",
        "\n",
        "        payload = {\n",
        "            \"run_id\": result.run_id,\n",
        "            \"execution_log_id\": result.execution_log_id,\n",
        "            \"suite_id\": suite_id,\n",
        "            \"timestamp\": now.isoformat(),\n",
        "            \"year\": now.year,\n",
        "            \"month\": now.month,\n",
        "            \"day\": now.day,\n",
        "            \"summary\": {\n",
        "                \"total\": result.total,\n",
        "                \"passed\": result.passed,\n",
        "                \"failed\": result.failed,\n",
        "                \"warned\": result.warned\n",
        "            },\n",
        "            \"scan_results\": scan_output.get('results', {}),\n",
        "            \"soda_logs\": scan_output.get('logs', ''),\n",
        "            \"yaml_content\": result.yaml_content\n",
        "        }\n",
        "\n",
        "        partition = f\"year={now.year}/month={now.month:02d}/day={now.day:02d}\"\n",
        "        path = f\"{self.config.lakehouse_path}/{self.config.logs_folder}/{partition}/execution_{result.run_id}.json\"\n",
        "\n",
        "        notebookutils.fs.put(path, json.dumps(payload, indent=2, default=str), overwrite=True)\n",
        "        return path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Orchestrator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DQCheckerOrchestrator:\n",
        "    \"\"\"\n",
        "    Main orchestrator for DQ Checker scan execution.\n",
        "\n",
        "    Coordinates reading checks, generating YAML, executing Soda scans,\n",
        "    and writing results to metadata DB and OneLake.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: DQConfig):\n",
        "        self.config = config\n",
        "        self.db = MetadataDB(config)\n",
        "        self.sources = DataSourceManager(self.db)\n",
        "        self.yaml_gen = SodaYAMLGenerator()\n",
        "        self.executor = SodaExecutor(config)\n",
        "        self.writer = ResultWriter(self.db, config)\n",
        "\n",
        "    def run(self, run_id: str) -> ScanResult:\n",
        "        \"\"\"\n",
        "        Execute DQ checks for configured suite/testcases.\n",
        "\n",
        "        Args:\n",
        "            run_id: Unique run identifier\n",
        "\n",
        "        Returns:\n",
        "            ScanResult with execution details\n",
        "        \"\"\"\n",
        "        result = ScanResult(run_id=run_id, execution_log_id=0)\n",
        "\n",
        "        try:\n",
        "            # Create execution log\n",
        "            print(f\"\\n[1/5] Creating execution log...\")\n",
        "            result.execution_log_id = self.writer.create_execution_log(\n",
        "                run_id, self.config.suite_id\n",
        "            )\n",
        "            print(f\"      Log ID: {result.execution_log_id}\")\n",
        "\n",
        "            # Fetch checks\n",
        "            print(f\"\\n[2/5] Fetching checks...\")\n",
        "            checks_df = self._fetch_checks()\n",
        "            print(f\"      Found {len(checks_df)} enabled checks\")\n",
        "\n",
        "            if checks_df.empty:\n",
        "                print(\"      No checks to execute.\")\n",
        "                return result\n",
        "\n",
        "            # Get data source and generate connection YAML\n",
        "            source_id = checks_df['source_id'].iloc[0]\n",
        "            source = self.sources.get(source_id)\n",
        "            cid, secret = source.get_credentials(self.config)\n",
        "            conn_yaml = source.get_soda_yaml(cid, secret)\n",
        "\n",
        "            # Generate check YAML\n",
        "            print(f\"\\n[3/5] Generating SodaCL YAML...\")\n",
        "            result.yaml_content = self.yaml_gen.generate(checks_df)\n",
        "            print(f\"      Generated {len(result.yaml_content)} bytes\")\n",
        "\n",
        "            # Execute scan\n",
        "            print(f\"\\n[4/5] Executing Soda scan against {source.source_name}...\")\n",
        "            scan_output = self.executor.execute(result.yaml_content, conn_yaml, run_id)\n",
        "            result.logs = scan_output['logs']\n",
        "\n",
        "            if scan_output['has_errors']:\n",
        "                result.has_errors = True\n",
        "                result.error_message = scan_output['error_logs']\n",
        "\n",
        "            # Parse results\n",
        "            result.results = self.executor.parse_results(scan_output['results'])\n",
        "            result.total = len(result.results)\n",
        "            result.passed = len([r for r in result.results if r['outcome'] == 'pass'])\n",
        "            result.failed = len([r for r in result.results if r['outcome'] == 'fail'])\n",
        "            result.warned = len([r for r in result.results if r['outcome'] == 'warn'])\n",
        "\n",
        "            # Write results\n",
        "            print(f\"\\n[5/5] Writing results...\")\n",
        "            self.writer.write_results(result.execution_log_id, run_id, result.results)\n",
        "            self.writer.update_execution_log(result.execution_log_id, result)\n",
        "\n",
        "            log_path = self.writer.write_to_onelake(result, self.config.suite_id, scan_output)\n",
        "            print(f\"      OneLake: {log_path}\")\n",
        "\n",
        "            # Summary\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"SCAN COMPLETE - Run ID: {run_id}\")\n",
        "            print(f\"  Total:  {result.total}\")\n",
        "            print(f\"  Passed: {result.passed}\")\n",
        "            print(f\"  Failed: {result.failed}\")\n",
        "            print(f\"  Warned: {result.warned}\")\n",
        "            print(f\"{'='*60}\")\n",
        "\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            result.error_message = str(e)\n",
        "            print(f\"\\nERROR: {e}\")\n",
        "\n",
        "            if result.execution_log_id:\n",
        "                try:\n",
        "                    self.writer.update_execution_log(result.execution_log_id, result)\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "            raise\n",
        "\n",
        "        finally:\n",
        "            self.db.close()\n",
        "\n",
        "    def _fetch_checks(self) -> pd.DataFrame:\n",
        "        \"\"\"Fetch checks based on suite_id or testcase_ids.\"\"\"\n",
        "        if self.config.testcase_ids:\n",
        "            ids = \",\".join(str(x) for x in self.config.testcase_ids)\n",
        "            where = f\"c.testcase_id IN ({ids})\"\n",
        "        else:\n",
        "            where = f\"\"\"\n",
        "                c.testcase_id IN (\n",
        "                    SELECT testcase_id FROM suites_testcases\n",
        "                    WHERE suite_id = {self.config.suite_id}\n",
        "                )\n",
        "            \"\"\"\n",
        "\n",
        "        return self.db.query(f\"\"\"\n",
        "            SELECT c.*, t.schema_name, t.source_id\n",
        "            FROM vw_checks_complete c\n",
        "            JOIN dq_testcases t ON c.testcase_id = t.testcase_id\n",
        "            WHERE {where} AND c.is_enabled = 1\n",
        "            ORDER BY c.check_id\n",
        "        \"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if config.smoke_test:\n",
        "    print(\"=\"*60)\n",
        "    print(\"SMOKE TEST MODE\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"Testing connection to metadata DB only.\")\n",
        "\n",
        "    db = MetadataDB(config)\n",
        "    try:\n",
        "        df = db.query(\"SELECT COUNT(*) AS count FROM dq_sources\")\n",
        "        print(f\"Connection OK - {df.iloc[0]['count']} data sources found\")\n",
        "    finally:\n",
        "        db.close()\n",
        "\n",
        "    result = ScanResult(run_id=RUN_ID, execution_log_id=0)\n",
        "else:\n",
        "    orchestrator = DQCheckerOrchestrator(config)\n",
        "    result = orchestrator.run(RUN_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pipeline Exit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fail pipeline if checks failed and FAIL_ON_ERROR is True\n",
        "if config.fail_on_error and result.failed > 0:\n",
        "    raise Exception(\n",
        "        f\"DQ validation failed: {result.failed} of {result.total} checks failed. \"\n",
        "        f\"Run ID: {result.run_id}\"\n",
        "    )\n",
        "\n",
        "print(f\"\\nExecution completed successfully. Run ID: {result.run_id}\")"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "jupyter",
      "jupyter_kernel_name": "python3.11"
    },
    "kernelspec": {
      "name": "jupyter",
      "display_name": "Jupyter"
    },
    "language_info": {
      "name": "python"
    },
    "microsoft": {
      "language": "python",
      "language_group": "jupyter_python"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "dependencies": {}
  },
  "nbformat": 4,
  "nbformat_minor": 5
}