{
  "nbformat_minor": 5,
  "cells": [
    {
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Fabric Python Notebook - DQ Checker Scan Executor\n",
        "# ============================================================================\n",
        "# Execute data quality checks against Fabric Data Warehouse using Soda Core.\n",
        "# Designed for Fabric Pipeline integration with parameterized execution.\n",
        "# ============================================================================\n"
      ],
      "outputs": [],
      "cell_type": "code"
    },
    {
      "metadata": {},
      "source": [
        "# DQ Checker - Soda Core Scan Executor\n",
        "\n",
        "**Execution Flow:**\n",
        "```\n",
        "Parameters → Read Config → Generate YAML → Execute Soda → Write Results\n",
        "```\n",
        "\n",
        "**Pipeline Integration:** Pass parameters via Fabric Pipeline activity.\n",
        "\n",
        "\n"
      ],
      "cell_type": "markdown"
    },
    {
      "execution_count": null,
      "metadata": {},
      "source": "# Install dependencies (cached after first run)\n%pip install soda-core-sqlserver --quiet\n",
      "outputs": [],
      "cell_type": "code"
    },
    {
      "metadata": {},
      "source": [
        "## Parameters\n",
        "\n",
        "Configure execution via Fabric Pipeline parameters or manual override.\n",
        "\n",
        "\n"
      ],
      "cell_type": "markdown"
    },
    {
      "execution_count": null,
      "metadata": {},
      "source": "# =============================================================================\n# PIPELINE PARAMETERS\n# =============================================================================\n# These values are set by Fabric Pipeline or manually for testing.\n# In Pipeline: Use \"Parameters\" section of notebook activity.\n\n# Execution scope\nSUITE_ID: int = 1                    # Suite to execute (0 = use TESTCASE_IDS)\nTESTCASE_IDS: str = \"\"               # Comma-separated testcase IDs (optional)\n\n# Pipeline behavior\nFAIL_ON_ERROR: bool = True           # Raise exception if any check fails\nSMOKE_TEST: bool = False             # True = test connection only, skip execution\n\n# =============================================================================\n# KEY VAULT CONFIGURATION\n# =============================================================================\n# All secrets come from Key Vault - credentials for target DWH (Soda checks)\n# NOTE: Metadata DB uses connect_to_artifact(\"soda_db\") - no credentials needed\nKEY_VAULT_URI: str = \"https://chwakv.vault.azure.net/\"\n\n# Secret names in Key Vault (for target DWH access via Soda)\nSECRET_CLIENT_ID: str = \"dq-checker-spn-client-id\"\nSECRET_CLIENT_SECRET: str = \"dq-checker-spn-secret\"\n\n# =============================================================================\n# ONELAKE OUTPUT\n# =============================================================================\nLAKEHOUSE_PATH: str = \"/lakehouse/default/Files\"\nLOGS_FOLDER: str = \"dq_logs\"\n",
      "outputs": [],
      "cell_type": "code"
    },
    {
      "metadata": {},
      "source": [
        "## Imports & Initialization\n",
        "\n",
        "\n"
      ],
      "cell_type": "markdown"
    },
    {
      "execution_count": null,
      "metadata": {},
      "source": "import json\nimport re\nimport uuid\nfrom datetime import datetime\nfrom typing import Dict, List, Optional, Any\nfrom dataclasses import dataclass, field\n\nimport pandas as pd\nimport pyodbc\nfrom soda.scan import Scan\nimport notebookutils\n\n# Generate unique run identifier\nRUN_ID = str(uuid.uuid4())[:8]\nprint(f\"DQ Checker Scan - Run ID: {RUN_ID}\")\n",
      "outputs": [],
      "cell_type": "code"
    },
    {
      "metadata": {},
      "source": [
        "## Configuration Loader\n",
        "\n",
        "\n"
      ],
      "cell_type": "markdown"
    },
    {
      "execution_count": null,
      "metadata": {},
      "source": "@dataclass\nclass DQConfig:\n    \"\"\"Configuration for DQ Checker execution.\"\"\"\n\n    # Credentials for target DWH (from Key Vault) - used by Soda for checks\n    client_id: str = \"\"\n    client_secret: str = \"\"\n\n    # Execution parameters\n    suite_id: int = 0\n    testcase_ids: List[int] = field(default_factory=list)\n    fail_on_error: bool = True\n    smoke_test: bool = False\n\n    # Output paths\n    lakehouse_path: str = \"/lakehouse/default/Files\"\n    logs_folder: str = \"dq_logs\"\n\n    @classmethod\n    def from_keyvault(cls, kv_uri: str, **overrides) -> \"DQConfig\":\n        \"\"\"\n        Load configuration from Azure Key Vault.\n        \n        Note: Metadata DB uses connect_to_artifact() (no credentials needed).\n        Only target DWH credentials are loaded from Key Vault.\n\n        Args:\n            kv_uri: Key Vault URI\n            **overrides: Override specific config values\n\n        Returns:\n            Configured DQConfig instance\n        \"\"\"\n        def get_secret(name: str, default: str = \"\") -> str:\n            try:\n                return notebookutils.credentials.getSecret(kv_uri, name)\n            except Exception as e:\n                print(f\"Warning: Could not get secret '{name}': {e}\")\n                return default\n\n        config = cls(\n            client_id=get_secret(SECRET_CLIENT_ID),\n            client_secret=get_secret(SECRET_CLIENT_SECRET),\n        )\n\n        # Apply overrides\n        for key, value in overrides.items():\n            if hasattr(config, key):\n                setattr(config, key, value)\n\n        return config\n\n\n# Load configuration\nconfig = DQConfig.from_keyvault(\n    KEY_VAULT_URI,\n    suite_id=SUITE_ID,\n    testcase_ids=[int(x.strip()) for x in TESTCASE_IDS.split(\",\") if x.strip()],\n    fail_on_error=FAIL_ON_ERROR,\n    smoke_test=SMOKE_TEST,\n    lakehouse_path=LAKEHOUSE_PATH,\n    logs_folder=LOGS_FOLDER,\n)\n\nprint(f\"Suite ID: {config.suite_id}\")\nprint(f\"Testcase IDs: {config.testcase_ids or 'All in suite'}\")\nprint(f\"Fail on Error: {config.fail_on_error}\")\n",
      "outputs": [],
      "cell_type": "code"
    },
    {
      "metadata": {},
      "source": "## Initialize soda_db Connection\n\nInitialize the T-SQL session for soda_db (metadata database). This must run before any code that uses the MetadataDB class.\n\n**Connection Architecture:**\n- **soda_db**: Uses `%tsql` magic (Fabric built-in auth, no credentials needed)\n- **Target DWH**: Uses pyodbc + Service Principal (for Soda checks)\n",
      "cell_type": "markdown"
    },
    {
      "cell_type": "code",
      "id": "c26jxvjcido",
      "source": "%%tsql -artifact soda_db -type SQLDatabase -session\n-- Initialize T-SQL session for soda_db metadata database\n-- This enables %tsql line magic in subsequent Python code\nSELECT 'soda_db session initialized' AS status;",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "execution_count": null,
      "metadata": {},
      "source": "class MetadataDB:\n    \"\"\"\n    Connection manager for DQ Checker metadata database (soda_db).\n\n    Uses %tsql magic command with pre-initialized session.\n    REQUIRES: Run %%tsql -artifact soda_db -type SQLDatabase -session\n              before instantiating this class.\n    \"\"\"\n\n    def __init__(self, config: DQConfig):\n        self.config = config\n        from IPython import get_ipython\n        self._ip = get_ipython()\n        if self._ip is None:\n            raise RuntimeError(\"MetadataDB requires IPython environment (Fabric notebook)\")\n\n    def query(self, sql: str) -> pd.DataFrame:\n        \"\"\"\n        Execute SELECT query and return DataFrame.\n        Uses %tsql line magic with pre-initialized soda_db session.\n        \"\"\"\n        # Clean SQL for line magic (single line, no extra whitespace)\n        clean_sql = ' '.join(sql.split())\n\n        # Execute via %tsql line magic\n        result = self._ip.run_line_magic('tsql', clean_sql)\n\n        # Handle different return types from Fabric\n        if result is None:\n            return pd.DataFrame()\n        if isinstance(result, pd.DataFrame):\n            return result\n        if hasattr(result, 'toPandas'):\n            return result.toPandas()\n        # Try to convert if it's a list/iterable\n        if hasattr(result, '__iter__') and not isinstance(result, str):\n            return pd.DataFrame(result)\n        return pd.DataFrame()\n\n    def execute(self, sql: str) -> Any:\n        \"\"\"\n        Execute SQL statement (INSERT/UPDATE/EXEC) and return first result.\n        Uses %tsql line magic with pre-initialized soda_db session.\n        \"\"\"\n        clean_sql = ' '.join(sql.split())\n        result = self._ip.run_line_magic('tsql', clean_sql)\n\n        if result is None:\n            return None\n        if hasattr(result, 'first'):\n            return result.first()\n        if isinstance(result, pd.DataFrame) and len(result) > 0:\n            return tuple(result.iloc[0])\n        return result\n\n    def close(self):\n        \"\"\"No-op - session lifecycle managed by %%tsql magic.\"\"\"\n        pass",
      "outputs": [],
      "cell_type": "code"
    },
    {
      "metadata": {},
      "source": [
        "## Data Source Manager\n",
        "\n",
        "\n"
      ],
      "cell_type": "markdown"
    },
    {
      "execution_count": null,
      "metadata": {},
      "source": [
        "@dataclass\n",
        "class DataSource:\n",
        "    \"\"\"Represents a data source from dq_sources table.\"\"\"\n",
        "    source_id: int\n",
        "    source_name: str\n",
        "    source_type: str\n",
        "    server_name: str\n",
        "    database_name: str\n",
        "    keyvault_uri: Optional[str] = None\n",
        "    client_id: Optional[str] = None\n",
        "    secret_name: Optional[str] = None\n",
        "\n",
        "    def get_credentials(self, default_config: DQConfig) -> tuple:\n",
        "        \"\"\"\n",
        "        Get credentials for this source.\n",
        "\n",
        "        Uses source-specific credentials if defined, otherwise falls back to defaults.\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (client_id, client_secret)\n",
        "        \"\"\"\n",
        "        # Use source-specific or default client_id\n",
        "        cid = self.client_id or default_config.client_id\n",
        "\n",
        "        # Get secret from source-specific or default Key Vault\n",
        "        kv_uri = self.keyvault_uri or KEY_VAULT_URI\n",
        "        secret_name = self.secret_name or SECRET_CLIENT_SECRET\n",
        "\n",
        "        secret = notebookutils.credentials.getSecret(kv_uri, secret_name)\n",
        "        return cid, secret\n",
        "\n",
        "    def get_soda_yaml(self, client_id: str, client_secret: str) -> str:\n",
        "        \"\"\"Generate Soda connection YAML for this source.\"\"\"\n",
        "        return f\"\"\"\n",
        "data_source {self.source_name}:\n",
        "  type: sqlserver\n",
        "  driver: ODBC Driver 18 for SQL Server\n",
        "  host: {self.server_name}\n",
        "  port: '1433'\n",
        "  database: {self.database_name}\n",
        "  authentication: ActiveDirectoryServicePrincipal\n",
        "  username: {client_id}\n",
        "  password: {client_secret}\n",
        "  encrypt: true\n",
        "  trust_server_certificate: false\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class DataSourceManager:\n",
        "    \"\"\"Manages data sources from metadata database.\"\"\"\n",
        "\n",
        "    def __init__(self, db: MetadataDB):\n",
        "        self.db = db\n",
        "        self._cache: Dict[int, DataSource] = {}\n",
        "\n",
        "    def get(self, source_id: int) -> DataSource:\n",
        "        \"\"\"Get data source by ID.\"\"\"\n",
        "        if source_id not in self._cache:\n",
        "            df = self.db.query(f\"\"\"\n",
        "                SELECT source_id, source_name, source_type, server_name,\n",
        "                       database_name, keyvault_uri, client_id, secret_name\n",
        "                FROM dq_sources WHERE source_id = {source_id}\n",
        "            \"\"\")\n",
        "            if df.empty:\n",
        "                raise ValueError(f\"Data source {source_id} not found\")\n",
        "            row = df.iloc[0]\n",
        "            self._cache[source_id] = DataSource(\n",
        "                source_id=row['source_id'],\n",
        "                source_name=row['source_name'],\n",
        "                source_type=row['source_type'] or 'fabric_warehouse',\n",
        "                server_name=row['server_name'],\n",
        "                database_name=row['database_name'],\n",
        "                keyvault_uri=row['keyvault_uri'],\n",
        "                client_id=row['client_id'],\n",
        "                secret_name=row['secret_name'],\n",
        "            )\n",
        "        return self._cache[source_id]\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "cell_type": "code"
    },
    {
      "metadata": {},
      "source": [
        "## YAML Generator\n",
        "\n",
        "\n"
      ],
      "cell_type": "markdown"
    },
    {
      "execution_count": null,
      "metadata": {},
      "source": [
        "class SodaYAMLGenerator:\n",
        "    \"\"\"\n",
        "    Generates SodaCL YAML from check definitions.\n",
        "\n",
        "    Supports all 22 Soda check types including freshness, schema,\n",
        "    reference, scalar comparison, and custom SQL.\n",
        "    \"\"\"\n",
        "\n",
        "    YAML_SPECIAL_CHARS = {':', '#', '{', '}', '[', ']', '&', '*', '!', '|', '>', '@', '`', '%'}\n",
        "\n",
        "    @staticmethod\n",
        "    def safe_value(value: Optional[str]) -> str:\n",
        "        \"\"\"Escape special characters for YAML output.\"\"\"\n",
        "        if value is None:\n",
        "            return ''\n",
        "        if not isinstance(value, str):\n",
        "            value = str(value)\n",
        "        value = value.strip()\n",
        "        if not value:\n",
        "            return ''\n",
        "\n",
        "        if '\\n' in value:\n",
        "            indented = '\\n        '.join(value.split('\\n'))\n",
        "            return f'|\\n        {indented}'\n",
        "\n",
        "        needs_quoting = (\n",
        "            any(c in value for c in SodaYAMLGenerator.YAML_SPECIAL_CHARS) or\n",
        "            value.startswith(\"'\") or value.startswith('\"') or\n",
        "            value.startswith(' ') or value.endswith(' ')\n",
        "        )\n",
        "\n",
        "        if needs_quoting:\n",
        "            escaped = value.replace('\\\\', '\\\\\\\\').replace('\"', '\\\\\"')\n",
        "            return f'\"{escaped}\"'\n",
        "\n",
        "        return value\n",
        "\n",
        "    def generate(self, checks_df: pd.DataFrame) -> str:\n",
        "        \"\"\"\n",
        "        Generate SodaCL YAML from checks DataFrame.\n",
        "\n",
        "        Args:\n",
        "            checks_df: DataFrame with check definitions from vw_checks_complete\n",
        "\n",
        "        Returns:\n",
        "            SodaCL YAML string\n",
        "        \"\"\"\n",
        "        if checks_df.empty:\n",
        "            return \"# No checks defined\\n\"\n",
        "\n",
        "        yaml_lines = []\n",
        "\n",
        "        for (schema_name, table_name), table_checks in checks_df.groupby(['schema_name', 'table_name']):\n",
        "            table_str = str(table_name)\n",
        "\n",
        "            # Handle special characters in table names\n",
        "            if ' ' in table_str or '-' in table_str:\n",
        "                fq_table = f'\"{table_str}\"'\n",
        "            elif pd.notna(schema_name) and '.' not in table_str:\n",
        "                fq_table = f\"{schema_name}.{table_str}\"\n",
        "            else:\n",
        "                fq_table = table_str\n",
        "\n",
        "            check_lines = []\n",
        "            for _, check in table_checks.iterrows():\n",
        "                check_lines.extend(self._generate_check(check))\n",
        "\n",
        "            if check_lines:\n",
        "                yaml_lines.append(f\"checks for {fq_table}:\")\n",
        "                yaml_lines.extend(check_lines)\n",
        "                yaml_lines.append(\"\")\n",
        "\n",
        "        return \"\\n\".join(yaml_lines)\n",
        "\n",
        "    def _generate_check(self, check: pd.Series) -> List[str]:\n",
        "        \"\"\"Generate YAML for a single check.\"\"\"\n",
        "        metric = check['metric']\n",
        "\n",
        "        # Route to specialized generators\n",
        "        generators = {\n",
        "            'freshness': self._gen_freshness,\n",
        "            'schema': self._gen_schema,\n",
        "            'reference': self._gen_reference,\n",
        "            'user_defined': self._gen_custom_sql,\n",
        "            'custom_sql': self._gen_custom_sql,\n",
        "            'scalar_comparison': self._gen_scalar,\n",
        "        }\n",
        "\n",
        "        if metric in generators:\n",
        "            return generators[metric](check)\n",
        "\n",
        "        return self._gen_standard(check)\n",
        "\n",
        "    def _gen_standard(self, check: pd.Series) -> List[str]:\n",
        "        \"\"\"Generate standard metric check.\"\"\"\n",
        "        lines = []\n",
        "        metric = check['metric']\n",
        "        column = check.get('column_name_quoted') or check.get('column_name')\n",
        "\n",
        "        column_metrics = [\n",
        "            'missing_count', 'missing_percent', 'duplicate_count', 'duplicate_percent',\n",
        "            'min', 'max', 'avg', 'sum', 'invalid_count', 'invalid_percent',\n",
        "            'valid_count', 'avg_length', 'min_length'\n",
        "        ]\n",
        "\n",
        "        if pd.notna(column) and metric in column_metrics:\n",
        "            lines.append(f\"  - {metric}({column}):\")\n",
        "        else:\n",
        "            lines.append(f\"  - {metric}:\")\n",
        "\n",
        "        check_name = self._format_check_name(check)\n",
        "        lines.append(f'      name: \"{check_name}\"')\n",
        "        lines.extend(self._gen_thresholds(check))\n",
        "\n",
        "        return lines\n",
        "\n",
        "    def _gen_thresholds(self, check: pd.Series) -> List[str]:\n",
        "        \"\"\"Generate warn/fail threshold lines.\"\"\"\n",
        "        lines = []\n",
        "\n",
        "        if pd.notna(check.get('warn_threshold')) and pd.notna(check.get('warn_comparison')):\n",
        "            op = '=' if check['warn_comparison'] == '==' else check['warn_comparison']\n",
        "            lines.append(f\"      warn: when {op} {check['warn_threshold']}\")\n",
        "\n",
        "        if pd.notna(check.get('fail_threshold')) and pd.notna(check.get('fail_comparison')):\n",
        "            op = '=' if check['fail_comparison'] == '==' else check['fail_comparison']\n",
        "            lines.append(f\"      fail: when {op} {check['fail_threshold']}\")\n",
        "\n",
        "        return lines\n",
        "\n",
        "    def _gen_freshness(self, check: pd.Series) -> List[str]:\n",
        "        \"\"\"Generate freshness check.\"\"\"\n",
        "        if not all(pd.notna(check.get(f)) for f in ['freshness_column', 'freshness_threshold_value', 'freshness_threshold_unit']):\n",
        "            return []\n",
        "\n",
        "        col = check['freshness_column']\n",
        "        val = int(check['freshness_threshold_value']) if float(check['freshness_threshold_value']).is_integer() else check['freshness_threshold_value']\n",
        "        unit = check['freshness_threshold_unit']\n",
        "\n",
        "        return [\n",
        "            f\"  - freshness({col}) < {val}{unit}:\",\n",
        "            f'      name: \"{self._format_check_name(check)}\"'\n",
        "        ]\n",
        "\n",
        "    def _gen_schema(self, check: pd.Series) -> List[str]:\n",
        "        \"\"\"Generate schema check.\"\"\"\n",
        "        lines = [\n",
        "            \"  - schema:\",\n",
        "            f'      name: \"{self._format_check_name(check)}\"'\n",
        "        ]\n",
        "\n",
        "        if pd.notna(check.get('schema_required_columns')):\n",
        "            try:\n",
        "                required = json.loads(check['schema_required_columns'])\n",
        "                if required:\n",
        "                    lines.append(\"      fail:\")\n",
        "                    lines.append(\"        when required column missing:\")\n",
        "                    for col in required:\n",
        "                        lines.append(f\"          - {col}\")\n",
        "            except json.JSONDecodeError:\n",
        "                pass\n",
        "\n",
        "        return lines\n",
        "\n",
        "    def _gen_reference(self, check: pd.Series) -> List[str]:\n",
        "        \"\"\"Generate reference integrity check.\"\"\"\n",
        "        if not all(pd.notna(check.get(f)) for f in ['reference_table', 'reference_column']):\n",
        "            return []\n",
        "\n",
        "        src_col = check.get('column_name_quoted') or check.get('column_name')\n",
        "        ref_table = check['reference_table']\n",
        "        ref_col = check.get('reference_column_quoted') or check['reference_column']\n",
        "        src_table = check['table_name']\n",
        "        schema = check.get('schema_name', 'dbo')\n",
        "\n",
        "        return [\n",
        "            \"  - failed rows:\",\n",
        "            f'      name: \"{self._format_check_name(check)}\"',\n",
        "            \"      fail query: |\",\n",
        "            f\"        SELECT * FROM {schema}.{src_table}\",\n",
        "            f\"        WHERE {src_col} IS NOT NULL\",\n",
        "            f\"          AND {src_col} NOT IN (SELECT {ref_col} FROM dbo.{ref_table})\"\n",
        "        ]\n",
        "\n",
        "    def _gen_custom_sql(self, check: pd.Series) -> List[str]:\n",
        "        \"\"\"Generate custom SQL check.\"\"\"\n",
        "        if not pd.notna(check.get('custom_sql_query')):\n",
        "            return []\n",
        "\n",
        "        sql = str(check['custom_sql_query']).strip()\n",
        "        metric_name = re.sub(r'[^a-zA-Z0-9_]', '_', check['check_name'].lower())\n",
        "        metric_name = re.sub(r'_+', '_', metric_name).strip('_')\n",
        "\n",
        "        threshold = \"= 0\"\n",
        "        if pd.notna(check.get('fail_comparison')) and pd.notna(check.get('fail_threshold')):\n",
        "            op = '=' if check['fail_comparison'] == '==' else check['fail_comparison']\n",
        "            threshold = f\"{op} {check['fail_threshold']}\"\n",
        "\n",
        "        lines = [\n",
        "            f\"  - {metric_name} {threshold}:\",\n",
        "            f'      name: \"{self._format_check_name(check)}\"',\n",
        "            f\"      {metric_name} query: |\"\n",
        "        ]\n",
        "        for sql_line in sql.split('\\n'):\n",
        "            lines.append(f\"        {sql_line}\")\n",
        "\n",
        "        return lines\n",
        "\n",
        "    def _gen_scalar(self, check: pd.Series) -> List[str]:\n",
        "        \"\"\"Generate scalar comparison check.\"\"\"\n",
        "        if not all(pd.notna(check.get(f)) for f in ['scalar_query_a', 'scalar_query_b']):\n",
        "            return []\n",
        "\n",
        "        qa = str(check['scalar_query_a']).strip()\n",
        "        qb = str(check['scalar_query_b']).strip()\n",
        "        op = check.get('scalar_operator', '==')\n",
        "\n",
        "        where_map = {\n",
        "            '==': 'query_a != query_b', '!=': 'query_a = query_b',\n",
        "            '>': 'query_a <= query_b', '>=': 'query_a < query_b',\n",
        "            '<': 'query_a >= query_b', '<=': 'query_a > query_b'\n",
        "        }\n",
        "\n",
        "        return [\n",
        "            \"  - failed rows:\",\n",
        "            f'      name: \"{self._format_check_name(check)}\"',\n",
        "            \"      fail query: |\",\n",
        "            \"        WITH comparison AS (\",\n",
        "            f\"          SELECT ({qa}) AS query_a, ({qb}) AS query_b\",\n",
        "            \"        )\",\n",
        "            \"        SELECT query_a, query_b, query_a - query_b AS difference\",\n",
        "            \"        FROM comparison\",\n",
        "            f\"        WHERE {where_map.get(op, 'query_a != query_b')}\"\n",
        "        ]\n",
        "\n",
        "    def _format_check_name(self, check: pd.Series) -> str:\n",
        "        \"\"\"Format check name with ID for result linking.\"\"\"\n",
        "        name = check['check_name']\n",
        "        if pd.notna(check.get('check_id')):\n",
        "            name = f\"{name} [check_id:{check['check_id']}]\"\n",
        "        return name\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "cell_type": "code"
    },
    {
      "metadata": {},
      "source": [
        "## Scan Executor\n",
        "\n",
        "\n"
      ],
      "cell_type": "markdown"
    },
    {
      "execution_count": null,
      "metadata": {},
      "source": [
        "@dataclass\n",
        "class ScanResult:\n",
        "    \"\"\"Results from a Soda scan execution.\"\"\"\n",
        "    run_id: str\n",
        "    execution_log_id: int\n",
        "    total: int = 0\n",
        "    passed: int = 0\n",
        "    failed: int = 0\n",
        "    warned: int = 0\n",
        "    has_errors: bool = False\n",
        "    error_message: Optional[str] = None\n",
        "    results: List[Dict] = field(default_factory=list)\n",
        "    yaml_content: str = \"\"\n",
        "    logs: str = \"\"\n",
        "\n",
        "\n",
        "class SodaExecutor:\n",
        "    \"\"\"Executes Soda scans against data sources.\"\"\"\n",
        "\n",
        "    def __init__(self, config: DQConfig):\n",
        "        self.config = config\n",
        "\n",
        "    def execute(self, yaml_content: str, connection_yaml: str, run_id: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Execute Soda scan.\n",
        "\n",
        "        Args:\n",
        "            yaml_content: SodaCL check definitions\n",
        "            connection_yaml: Soda data source configuration\n",
        "            run_id: Unique run identifier\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with scan results, logs, and error status\n",
        "        \"\"\"\n",
        "        scan = Scan()\n",
        "        scan.set_data_source_name(\"fabric_dwh\")\n",
        "        scan.set_scan_definition_name(f\"dq_checker_{run_id}\")\n",
        "        scan.add_configuration_yaml_str(connection_yaml)\n",
        "        scan.add_sodacl_yaml_str(yaml_content)\n",
        "\n",
        "        scan.execute()\n",
        "\n",
        "        return {\n",
        "            \"results\": scan.get_scan_results(),\n",
        "            \"logs\": scan.get_logs_text(),\n",
        "            \"has_errors\": scan.has_error_logs(),\n",
        "            \"error_logs\": scan.get_error_logs_text() if scan.has_error_logs() else None\n",
        "        }\n",
        "\n",
        "    def parse_results(self, scan_results: Dict) -> List[Dict]:\n",
        "        \"\"\"Extract structured results from Soda scan output.\"\"\"\n",
        "        results = []\n",
        "\n",
        "        for check in scan_results.get('checks', []):\n",
        "            check_name = check.get('name', '')\n",
        "            check_id_match = re.search(r'\\[check_id:(\\d+)\\]', check_name)\n",
        "\n",
        "            diagnostics = check.get('diagnostics', {})\n",
        "\n",
        "            results.append({\n",
        "                'check_id': int(check_id_match.group(1)) if check_id_match else None,\n",
        "                'check_name': check_name,\n",
        "                'outcome': check.get('outcome', 'unknown'),\n",
        "                'value': diagnostics.get('value', check.get('value'))\n",
        "            })\n",
        "\n",
        "        return results\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "cell_type": "code"
    },
    {
      "metadata": {},
      "source": [
        "## Result Writer\n",
        "\n",
        "\n"
      ],
      "cell_type": "markdown"
    },
    {
      "execution_count": null,
      "metadata": {},
      "source": [
        "class ResultWriter:\n",
        "    \"\"\"Writes scan results to metadata DB and OneLake.\"\"\"\n",
        "\n",
        "    def __init__(self, db: MetadataDB, config: DQConfig):\n",
        "        self.db = db\n",
        "        self.config = config\n",
        "\n",
        "    def create_execution_log(self, run_id: str, suite_id: int) -> int:\n",
        "        \"\"\"Create execution log entry.\"\"\"\n",
        "        result = self.db.execute(\n",
        "            f\"EXEC sp_create_execution_log @run_id='{run_id}', @suite_id={suite_id}\"\n",
        "        )\n",
        "        return int(result[0])\n",
        "\n",
        "    def write_results(self, log_id: int, run_id: str, results: List[Dict]):\n",
        "        \"\"\"Write individual check results.\"\"\"\n",
        "        conn = self.db.connect()\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        for r in results:\n",
        "            name = str(r['check_name']).replace(\"'\", \"''\") if r['check_name'] else ''\n",
        "            outcome = str(r['outcome']).replace(\"'\", \"''\") if r['outcome'] else ''\n",
        "            check_id = r['check_id'] if r['check_id'] else 'NULL'\n",
        "            value = r['value'] if r['value'] is not None else 'NULL'\n",
        "\n",
        "            cursor.execute(f\"\"\"\n",
        "                EXEC sp_insert_result\n",
        "                    @run_id='{run_id}', @execution_log_id={log_id},\n",
        "                    @check_id={check_id}, @check_name='{name}',\n",
        "                    @check_outcome='{outcome}', @check_value={value}\n",
        "            \"\"\")\n",
        "            cursor.fetchone()\n",
        "\n",
        "        conn.commit()\n",
        "\n",
        "    def update_execution_log(self, log_id: int, result: ScanResult):\n",
        "        \"\"\"Update execution log with final status.\"\"\"\n",
        "        status = 'failed' if result.error_message else 'completed'\n",
        "        has_failures = 1 if result.failed > 0 else 0\n",
        "\n",
        "        yaml_esc = result.yaml_content.replace(\"'\", \"''\")\n",
        "        error_esc = result.error_message.replace(\"'\", \"''\") if result.error_message else ''\n",
        "        error_param = f\"'{error_esc}'\" if result.error_message else 'NULL'\n",
        "\n",
        "        self.db.execute(f\"\"\"\n",
        "            EXEC sp_update_execution_log\n",
        "                @execution_log_id={log_id}, @status='{status}',\n",
        "                @total_checks={result.total}, @checks_passed={result.passed},\n",
        "                @checks_failed={result.failed}, @checks_warned={result.warned},\n",
        "                @has_failures={has_failures}, @generated_yaml='{yaml_esc}',\n",
        "                @error_message={error_param}\n",
        "        \"\"\")\n",
        "\n",
        "    def write_to_onelake(self, result: ScanResult, suite_id: int, scan_output: Dict) -> str:\n",
        "        \"\"\"Write full results to OneLake with Hive-style partitioning.\"\"\"\n",
        "        now = datetime.utcnow()\n",
        "\n",
        "        payload = {\n",
        "            \"run_id\": result.run_id,\n",
        "            \"execution_log_id\": result.execution_log_id,\n",
        "            \"suite_id\": suite_id,\n",
        "            \"timestamp\": now.isoformat(),\n",
        "            \"year\": now.year,\n",
        "            \"month\": now.month,\n",
        "            \"day\": now.day,\n",
        "            \"summary\": {\n",
        "                \"total\": result.total,\n",
        "                \"passed\": result.passed,\n",
        "                \"failed\": result.failed,\n",
        "                \"warned\": result.warned\n",
        "            },\n",
        "            \"scan_results\": scan_output.get('results', {}),\n",
        "            \"soda_logs\": scan_output.get('logs', ''),\n",
        "            \"yaml_content\": result.yaml_content\n",
        "        }\n",
        "\n",
        "        partition = f\"year={now.year}/month={now.month:02d}/day={now.day:02d}\"\n",
        "        path = f\"{self.config.lakehouse_path}/{self.config.logs_folder}/{partition}/execution_{result.run_id}.json\"\n",
        "\n",
        "        notebookutils.fs.put(path, json.dumps(payload, indent=2, default=str), overwrite=True)\n",
        "        return path\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "cell_type": "code"
    },
    {
      "metadata": {},
      "source": [
        "## Orchestrator\n",
        "\n",
        "\n"
      ],
      "cell_type": "markdown"
    },
    {
      "execution_count": null,
      "metadata": {},
      "source": [
        "class DQCheckerOrchestrator:\n",
        "    \"\"\"\n",
        "    Main orchestrator for DQ Checker scan execution.\n",
        "\n",
        "    Coordinates reading checks, generating YAML, executing Soda scans,\n",
        "    and writing results to metadata DB and OneLake.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: DQConfig):\n",
        "        self.config = config\n",
        "        self.db = MetadataDB(config)\n",
        "        self.sources = DataSourceManager(self.db)\n",
        "        self.yaml_gen = SodaYAMLGenerator()\n",
        "        self.executor = SodaExecutor(config)\n",
        "        self.writer = ResultWriter(self.db, config)\n",
        "\n",
        "    def run(self, run_id: str) -> ScanResult:\n",
        "        \"\"\"\n",
        "        Execute DQ checks for configured suite/testcases.\n",
        "\n",
        "        Args:\n",
        "            run_id: Unique run identifier\n",
        "\n",
        "        Returns:\n",
        "            ScanResult with execution details\n",
        "        \"\"\"\n",
        "        result = ScanResult(run_id=run_id, execution_log_id=0)\n",
        "\n",
        "        try:\n",
        "            # Create execution log\n",
        "            print(f\"\\n[1/5] Creating execution log...\")\n",
        "            result.execution_log_id = self.writer.create_execution_log(\n",
        "                run_id, self.config.suite_id\n",
        "            )\n",
        "            print(f\"      Log ID: {result.execution_log_id}\")\n",
        "\n",
        "            # Fetch checks\n",
        "            print(f\"\\n[2/5] Fetching checks...\")\n",
        "            checks_df = self._fetch_checks()\n",
        "            print(f\"      Found {len(checks_df)} enabled checks\")\n",
        "\n",
        "            if checks_df.empty:\n",
        "                print(\"      No checks to execute.\")\n",
        "                return result\n",
        "\n",
        "            # Get data source and generate connection YAML\n",
        "            source_id = checks_df['source_id'].iloc[0]\n",
        "            source = self.sources.get(source_id)\n",
        "            cid, secret = source.get_credentials(self.config)\n",
        "            conn_yaml = source.get_soda_yaml(cid, secret)\n",
        "\n",
        "            # Generate check YAML\n",
        "            print(f\"\\n[3/5] Generating SodaCL YAML...\")\n",
        "            result.yaml_content = self.yaml_gen.generate(checks_df)\n",
        "            print(f\"      Generated {len(result.yaml_content)} bytes\")\n",
        "\n",
        "            # Execute scan\n",
        "            print(f\"\\n[4/5] Executing Soda scan against {source.source_name}...\")\n",
        "            scan_output = self.executor.execute(result.yaml_content, conn_yaml, run_id)\n",
        "            result.logs = scan_output['logs']\n",
        "\n",
        "            if scan_output['has_errors']:\n",
        "                result.has_errors = True\n",
        "                result.error_message = scan_output['error_logs']\n",
        "\n",
        "            # Parse results\n",
        "            result.results = self.executor.parse_results(scan_output['results'])\n",
        "            result.total = len(result.results)\n",
        "            result.passed = len([r for r in result.results if r['outcome'] == 'pass'])\n",
        "            result.failed = len([r for r in result.results if r['outcome'] == 'fail'])\n",
        "            result.warned = len([r for r in result.results if r['outcome'] == 'warn'])\n",
        "\n",
        "            # Write results\n",
        "            print(f\"\\n[5/5] Writing results...\")\n",
        "            self.writer.write_results(result.execution_log_id, run_id, result.results)\n",
        "            self.writer.update_execution_log(result.execution_log_id, result)\n",
        "\n",
        "            log_path = self.writer.write_to_onelake(result, self.config.suite_id, scan_output)\n",
        "            print(f\"      OneLake: {log_path}\")\n",
        "\n",
        "            # Summary\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"SCAN COMPLETE - Run ID: {run_id}\")\n",
        "            print(f\"  Total:  {result.total}\")\n",
        "            print(f\"  Passed: {result.passed}\")\n",
        "            print(f\"  Failed: {result.failed}\")\n",
        "            print(f\"  Warned: {result.warned}\")\n",
        "            print(f\"{'='*60}\")\n",
        "\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            result.error_message = str(e)\n",
        "            print(f\"\\nERROR: {e}\")\n",
        "\n",
        "            if result.execution_log_id:\n",
        "                try:\n",
        "                    self.writer.update_execution_log(result.execution_log_id, result)\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "            raise\n",
        "\n",
        "        finally:\n",
        "            self.db.close()\n",
        "\n",
        "    def _fetch_checks(self) -> pd.DataFrame:\n",
        "        \"\"\"Fetch checks based on suite_id or testcase_ids.\"\"\"\n",
        "        if self.config.testcase_ids:\n",
        "            ids = \",\".join(str(x) for x in self.config.testcase_ids)\n",
        "            where = f\"c.testcase_id IN ({ids})\"\n",
        "        else:\n",
        "            where = f\"\"\"\n",
        "                c.testcase_id IN (\n",
        "                    SELECT testcase_id FROM suites_testcases\n",
        "                    WHERE suite_id = {self.config.suite_id}\n",
        "                )\n",
        "            \"\"\"\n",
        "\n",
        "        return self.db.query(f\"\"\"\n",
        "            SELECT c.*, t.schema_name, t.source_id\n",
        "            FROM vw_checks_complete c\n",
        "            JOIN dq_testcases t ON c.testcase_id = t.testcase_id\n",
        "            WHERE {where} AND c.is_enabled = 1\n",
        "            ORDER BY c.check_id\n",
        "        \"\"\")\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "cell_type": "code"
    },
    {
      "metadata": {},
      "source": [
        "## Execution\n",
        "\n",
        "\n"
      ],
      "cell_type": "markdown"
    },
    {
      "execution_count": null,
      "metadata": {},
      "source": [
        "if config.smoke_test:\n",
        "    print(\"=\"*60)\n",
        "    print(\"SMOKE TEST MODE\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"Testing connection to metadata DB only.\")\n",
        "\n",
        "    db = MetadataDB(config)\n",
        "    try:\n",
        "        df = db.query(\"SELECT COUNT(*) AS count FROM dq_sources\")\n",
        "        print(f\"Connection OK - {df.iloc[0]['count']} data sources found\")\n",
        "    finally:\n",
        "        db.close()\n",
        "\n",
        "    result = ScanResult(run_id=RUN_ID, execution_log_id=0)\n",
        "else:\n",
        "    orchestrator = DQCheckerOrchestrator(config)\n",
        "    result = orchestrator.run(RUN_ID)\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "cell_type": "code"
    },
    {
      "metadata": {},
      "source": [
        "## Pipeline Exit\n",
        "\n",
        "\n"
      ],
      "cell_type": "markdown"
    },
    {
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Fail pipeline if checks failed and FAIL_ON_ERROR is True\n",
        "if config.fail_on_error and result.failed > 0:\n",
        "    raise Exception(\n",
        "        f\"DQ validation failed: {result.failed} of {result.total} checks failed. \"\n",
        "        f\"Run ID: {result.run_id}\"\n",
        "    )\n",
        "\n",
        "print(f\"\\nExecution completed successfully. Run ID: {result.run_id}\")\n",
        "\n"
      ],
      "outputs": [],
      "cell_type": "code"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Jupyter",
      "name": "jupyter"
    },
    "spark_compute": {
      "session_options": {
        "conf": {
          "spark.synapse.nbs.session.timeout": "1200000"
        }
      },
      "compute_id": "/trident/default"
    },
    "language_info": {
      "name": "python"
    },
    "microsoft": {
      "language": "python",
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "language_group": "jupyter_python"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "dependencies": {},
    "kernel_info": {
      "name": "jupyter",
      "jupyter_kernel_name": "python3.11"
    }
  },
  "nbformat": 4
}